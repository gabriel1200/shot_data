{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fefb248-1691-4e4a-8c89-cea32dc6e70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21096/661379562.py:56: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  pd.DataFrame(g.sum()[f'{playtype}_PTS']).reset_index(drop=False),\n",
      "/tmp/ipykernel_21096/661379562.py:56: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  pd.DataFrame(g.sum()[f'{playtype}_PTS']).reset_index(drop=False),\n",
      "/tmp/ipykernel_21096/661379562.py:56: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  pd.DataFrame(g.sum()[f'{playtype}_PTS']).reset_index(drop=False),\n",
      "/tmp/ipykernel_21096/661379562.py:56: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  pd.DataFrame(g.sum()[f'{playtype}_PTS']).reset_index(drop=False),\n",
      "/tmp/ipykernel_21096/661379562.py:56: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  pd.DataFrame(g.sum()[f'{playtype}_PTS']).reset_index(drop=False),\n",
      "/tmp/ipykernel_21096/661379562.py:56: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  pd.DataFrame(g.sum()[f'{playtype}_PTS']).reset_index(drop=False),\n",
      "/tmp/ipykernel_21096/661379562.py:56: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  pd.DataFrame(g.sum()[f'{playtype}_PTS']).reset_index(drop=False),\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unidecode\n",
    "import requests\n",
    "import time\n",
    "\n",
    "headers = {\n",
    "    'Host': 'stats.nba.com',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:72.0) Gecko/20100101 Firefox/72.0',\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'x-nba-stats-origin': 'stats',\n",
    "    'x-nba-stats-token': 'true',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Referer': 'https://stats.nba.com/',\n",
    "    'Pragma': 'no-cache',\n",
    "    'Cache-Control': 'no-cache'\n",
    "}\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for ssn in ['2024-25']:\n",
    "\n",
    "    # Synergy Playtypes\n",
    "    playtypes = [\n",
    "        'Isolation', 'PRBallHandler', 'PRRollMan', 'Spotup', 'Postup', 'Transition', 'Handoff', 'Cut', 'OffScreen', 'Misc'\n",
    "    ]\n",
    "\n",
    "    synergy_data = []\n",
    "\n",
    "    for playtype in playtypes:\n",
    "        url = f'https://stats.nba.com/stats/synergyplaytypes?LeagueID=00&PerMode=Totals&PlayType={playtype}&PlayerOrTeam=P&SeasonType=Regular+Season&SeasonYear={ssn}&TypeGrouping=offensive'\n",
    "        response = requests.get(url, headers=headers).json()\n",
    "        time.sleep(1)\n",
    "\n",
    "        data = response['resultSets'][0]['rowSet']\n",
    "        columns = response['resultSets'][0]['headers']\n",
    "\n",
    "        df = pd.DataFrame.from_records(data, columns=columns)\n",
    "\n",
    "        # Rename columns for clarity\n",
    "        df.rename(columns={\n",
    "            'POSS_PCT': f'{playtype}_POSS_PCT',\n",
    "            'EFG_PCT': f'{playtype}_EFG_PCT',\n",
    "            'PTS': f'{playtype}_PTS'\n",
    "        }, inplace=True)\n",
    "\n",
    "        # Weighted averages and summing points\n",
    "        g = df.groupby(['PLAYER_NAME'])\n",
    "        df = pd.merge(\n",
    "            g.apply(lambda x: pd.Series(\n",
    "                np.average(x[[f'{playtype}_POSS_PCT', f'{playtype}_EFG_PCT']], weights=x['POSS'], axis=0),\n",
    "                [f'{playtype}_POSS_PCT', f'{playtype}_EFG_PCT']\n",
    "            )).reset_index(drop=False),\n",
    "            pd.DataFrame(g.sum()[f'{playtype}_PTS']).reset_index(drop=False),\n",
    "            on='PLAYER_NAME'\n",
    "        )\n",
    "\n",
    "        synergy_data.append(df)\n",
    "\n",
    "    # Merge all synergy playtype data\n",
    "    synergy_df = synergy_data[0]\n",
    "    for df in synergy_data[1:]:\n",
    "        synergy_df = pd.merge(synergy_df, df, on='PLAYER_NAME', how='outer')\n",
    "\n",
    "    synergy_df.fillna(0, inplace=True)\n",
    "    synergy_df['SEASON'] = ssn\n",
    "\n",
    "    df_list.append(synergy_df)\n",
    "    print(f\"Year {ssn} is finished.\")\n",
    "\n",
    "# Combine all seasons\n",
    "df = pd.concat(df_list).reset_index(drop=True)\n",
    "\n",
    "# Preview the data\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.cluster.hierarchy as shc\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#testdf = df[(df.MPG > 23) & (df.GP > 15) & (df.SEASON == '2022-23')].reset_index(drop=True)\n",
    "testdf = df.reset_index(drop=True)\n",
    "\n",
    "features = [x for x in df.columns if (x != 'PLAYER_NAME') &  (x != 'POSITION') & (x != 'SEASON')]\n",
    "\n",
    "x = testdf.loc[:, features].values\n",
    "y = testdf.loc[:,['PLAYER_NAME']].values\n",
    "\n",
    "x = StandardScaler().fit_transform(x) # standardize all values\n",
    "\n",
    "pca = PCA(n_components=0.99)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "\n",
    "plt.figure(figsize=(10,65))\n",
    "plt.title('2024-25 NBA Hierarchical Clustering Dendrogram')\n",
    "dend = shc.dendrogram(shc.linkage(x, method='ward'), labels=list(testdf.PLAYER_NAME), orientation='left')\n",
    "\n",
    "plt.yticks(fontsize=8)\n",
    "plt.xlabel('Height')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot in PNG format\n",
    "plt.savefig(\"nba_hierarchical_clustering_dendrogram.png\", format='png', dpi=300)\n",
    "\n",
    "# Optionally, display the plot as well\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "import pandas as pd\n",
    "\n",
    "# Compute linkage matrix (using Ward's method as in your dendrogram)\n",
    "linkage_matrix = shc.linkage(x, method='ward')\n",
    "\n",
    "# Set a distance threshold (adjust based on your dendrogram)\n",
    "distance_threshold = 30  # Adjust based on large vertical gaps in the dendrogram\n",
    "\n",
    "# Find clusters\n",
    "clusters = fcluster(linkage_matrix, distance_threshold, criterion='distance')\n",
    "\n",
    "# Add cluster labels to the dataframe\n",
    "testdf['Cluster'] = clusters\n",
    "\n",
    "# Print cluster counts\n",
    "print(testdf['Cluster'].value_counts())\n",
    "\n",
    "# Save the cluster assignments\n",
    "testdf[['PLAYER_NAME', 'Cluster']].to_csv('nba_hierarchical_clusters.csv', index=False)\n",
    "\n",
    "# Exclude non-numeric columns for the cluster summary\n",
    "numeric_features = testdf.select_dtypes(include=[np.number])  # Keep only numeric columns\n",
    "numeric_features['Cluster'] = testdf['Cluster']  # Add Cluster column back\n",
    "\n",
    "# Calculate the mean for each numeric feature grouped by Cluster\n",
    "cluster_summary = numeric_features.groupby('Cluster').mean()\n",
    "\n",
    "# Print the feature summary for each cluster\n",
    "for cluster_id in cluster_summary.index:\n",
    "    print(f\"Cluster {cluster_id} Summary:\")\n",
    "    print(cluster_summary.loc[cluster_id])\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Optionally, save the cluster summary to a CSV\n",
    "cluster_summary.to_csv('nba_hierarchical_cluster_summary.csv', index=True)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Use the processed data after PCA\n",
    "x = testdf.loc[:, features].values\n",
    "x = StandardScaler().fit_transform(x)\n",
    "pca = PCA(n_components=0.99)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "\n",
    "# Determine optimal number of clusters using the elbow method\n",
    "inertia = []\n",
    "silhouette_scores = []\n",
    "k_values = range(2, 30)  # Testing for 2 to 10 clusters\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10, max_iter=500)\n",
    "    kmeans.fit(principalComponents)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(principalComponents, kmeans.labels_))\n",
    "\n",
    "# Plotting the Elbow Method\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(k_values, inertia, marker='o')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plotting Silhouette Scores\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(k_values, silhouette_scores, marker='o', color='green')\n",
    "plt.title('Silhouette Scores for Different k')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Choose the optimal number of clusters (e.g., based on plots)\n",
    "optimal_k = 13  # Replace with the chosen k based on visual inspection\n",
    "\n",
    "# Fit K-Means with the optimal number of clusters\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10, max_iter=500)\n",
    "kmeans.fit(principalComponents)\n",
    "\n",
    "# Add cluster labels to the dataframe\n",
    "testdf['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Save results to a CSV (optional)\n",
    "testdf[['PLAYER_NAME', 'Cluster']].to_csv('nba_kmeans_clusters.csv', index=False)\n",
    "\n",
    "# Visualize the clusters in the first two PCA components\n",
    "plt.figure(figsize=(10, 7))\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_points = principalComponents[kmeans.labels_ == cluster]\n",
    "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f'Cluster {cluster}')\n",
    "\n",
    "plt.title('K-Means Clustering Visualization')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Use the processed data\n",
    "x = testdf.loc[:, features].values\n",
    "x = StandardScaler().fit_transform(x)\n",
    "pca = PCA(n_components=0.99)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "\n",
    "# Choose the optimal number of clusters\n",
    "optimal_k = 13\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10, max_iter=500)\n",
    "kmeans.fit(principalComponents)\n",
    "\n",
    "# Add cluster labels and PCA components to the dataframe\n",
    "testdf['Cluster'] = kmeans.labels_\n",
    "testdf['PCA1'] = principalComponents[:, 0]  # First principal component\n",
    "testdf['PCA2'] = principalComponents[:, 1]  # Second principal component\n",
    "\n",
    "# Define consistent color mapping for clusters\n",
    "color_map = px.colors.qualitative.Set1  # Adjust this if more than 10 clusters\n",
    "cluster_colors = {cluster: color_map[i % len(color_map)] for i, cluster in enumerate(sorted(testdf['Cluster'].unique()))}\n",
    "\n",
    "# Create the base scatter plot\n",
    "fig = px.scatter(\n",
    "    testdf,\n",
    "    x='PCA1',\n",
    "    y='PCA2',\n",
    "    color='Cluster',\n",
    "    color_discrete_map=cluster_colors,\n",
    "    hover_data=['PLAYER_NAME'],  # Show player names on hover\n",
    "    title='K-Means Clustering Visualization',\n",
    "    labels={'PCA1': 'Principal Component 1', 'PCA2': 'Principal Component 2'},\n",
    ")\n",
    "\n",
    "# Add a dropdown menu to filter clusters\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        {\n",
    "            \"buttons\": [\n",
    "                {\n",
    "                    \"label\": f\"Show Cluster {cluster}\",\n",
    "                    \"method\": \"update\",\n",
    "                    \"args\": [\n",
    "                        {\n",
    "                            \"marker\": {\"opacity\": [1 if c == cluster else 0.2 for c in testdf['Cluster']]},\n",
    "                        },\n",
    "                        {\"title\": f\"K-Means Clustering: Cluster {cluster} Highlighted\"},\n",
    "                    ],\n",
    "                }\n",
    "                for cluster in sorted(testdf['Cluster'].unique())\n",
    "            ]\n",
    "            + [\n",
    "                {\n",
    "                    \"label\": \"Show All Clusters\",\n",
    "                    \"method\": \"update\",\n",
    "                    \"args\": [\n",
    "                        {\n",
    "                            \"marker\": {\"opacity\": [1 for _ in testdf['Cluster']]},\n",
    "                        },\n",
    "                        {\"title\": \"K-Means Clustering: All Clusters\"},\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            \"direction\": \"down\",\n",
    "            \"showactive\": True,\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "# Exclude non-numeric columns for the feature summary\n",
    "numeric_features = testdf.select_dtypes(include=[np.number])\n",
    "\n",
    "# Add the Cluster column back to the numeric_features dataframe\n",
    "numeric_features['Cluster'] = testdf['Cluster']\n",
    "\n",
    "# Calculate the mean for each numeric feature grouped by Cluster\n",
    "feature_summary = numeric_features.groupby('Cluster').mean()\n",
    "\n",
    "# Print the feature summary for each cluster\n",
    "for cluster_id in range(optimal_k):\n",
    "    print(f\"Cluster {cluster_id} Summary:\")\n",
    "    print(feature_summary.loc[cluster_id])\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Optionally, save the feature summary to a CSV\n",
    "feature_summary.to_csv('cluster_feature_summary.csv', index=True)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca4c2a2-b686-40dc-9b00-d7ae67fa233c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
