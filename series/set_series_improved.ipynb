{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb825ed-9442-4a97-9bff-4576e937472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from nba_api.stats.static import teams\n",
    "import io\n",
    "\n",
    "def get_dates(start_year=2025, end_year=2026):\n",
    "    dates = []\n",
    "    for year in range(start_year, end_year):\n",
    "        for team in teams.get_teams():\n",
    "            team_id = team['id']\n",
    "            path = f'../team/{year}ps/{team_id}.csv'\n",
    "            if os.path.exists(path):\n",
    "                try:\n",
    "                    df = pd.read_csv(path)\n",
    "                    required_cols = {'PLAYER_ID', 'HTM', 'VTM', 'GAME_DATE', 'GAME_ID'}\n",
    "                    if required_cols.issubset(df.columns):\n",
    "                        df = df[['PLAYER_ID', 'HTM', 'VTM', 'GAME_DATE', 'GAME_ID']]\n",
    "                        df['year'] = year\n",
    "                        df.drop_duplicates(inplace=True)\n",
    "                        dates.append(df)\n",
    "                except Exception:\n",
    "                    continue\n",
    "    if dates:\n",
    "        return pd.concat(dates).drop_duplicates(subset='GAME_ID')\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def fetch_game_csvs(dateframe, save_dir='game_data'):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    all_game_data = []\n",
    "    for _, row in dateframe.iterrows():\n",
    "        year = int(row['year'])\n",
    "        game_id = row['GAME_ID']\n",
    "        url = f'https://raw.githubusercontent.com/gabriel1200/player_sheets/refs/heads/master/game_report/{year}/{game_id}.csv'\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            if len(response.text.strip()) == 0:\n",
    "                continue\n",
    "            df = pd.read_csv(io.StringIO(response.text))\n",
    "            df['GAME_ID'] = game_id\n",
    "            df['date'] = row['GAME_DATE']\n",
    "            df['HTM'] = row['HTM']\n",
    "            df['VTM'] = row['VTM']\n",
    "            df['year'] = year\n",
    "            all_game_data.append(df)\n",
    "            with open(os.path.join(save_dir, f'{year}_{game_id}.csv'), 'w', encoding='utf-8') as f:\n",
    "                f.write(response.text)\n",
    "        except Exception:\n",
    "            continue\n",
    "    if all_game_data:\n",
    "        return pd.concat(all_game_data, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def process_and_save_series_data(df, dateframe):\n",
    "    df.rename(columns={'GAME_DATE': 'date'}, inplace=True)\n",
    "    if 'opp_team' in df.columns:\n",
    "        df.drop(columns='opp_team', inplace=True)\n",
    "    home = df[df.HTM == df.TEAM_ABBREVIATION].copy()\n",
    "    away = df[df.VTM == df.TEAM_ABBREVIATION].copy()\n",
    "    none = df[df.HTM.isna()].copy().reset_index(drop=True)\n",
    "    home.drop(columns='HTM', inplace=True)\n",
    "    home.rename(columns={'VTM': 'opp_team'}, inplace=True)\n",
    "    away.drop(columns='VTM', inplace=True)\n",
    "    away.rename(columns={'HTM': 'opp_team'}, inplace=True)\n",
    "    home.drop_duplicates(inplace=True)\n",
    "    away.drop_duplicates(inplace=True)\n",
    "    frames = [home, away]\n",
    "    if len(none) > 0:\n",
    "        frames.append(none)\n",
    "    df = pd.concat(frames, ignore_index=True)\n",
    "    oppframe = df[['TEAM_ID', 'date', 'opp_team']].dropna(subset=['opp_team']).drop_duplicates()\n",
    "    df.drop(columns='opp_team', inplace=True)\n",
    "    df = df.merge(oppframe, on=['TEAM_ID', 'date'], how='left')\n",
    "    df['team'] = df['TEAM_ABBREVIATION']\n",
    "    teammap = dict(zip(df['TEAM_ABBREVIATION'], df['TEAM_ID']))\n",
    "    player_index = df[['PLAYER_NAME', 'PLAYER_ID', 'team', 'TEAM_ID', 'opp_team', 'year']].copy()\n",
    "    player_index['opp_id'] = player_index['opp_team'].map(teammap)\n",
    "    player_index.drop_duplicates(inplace=True)\n",
    "    index_path = 'series_index_players.csv'\n",
    "    if os.path.exists(index_path):\n",
    "        existing_index = pd.read_csv(index_path)\n",
    "        combined = pd.concat([existing_index, player_index], ignore_index=True)\n",
    "        combined.drop_duplicates(subset=['PLAYER_ID', 'team', 'TEAM_ID', 'opp_team', 'year'], keep='last', inplace=True)\n",
    "        combined.to_csv(index_path, index=False)\n",
    "    else:\n",
    "        player_index.to_csv(index_path, index=False)\n",
    "    df = df.dropna(subset=['opp_team'])\n",
    "    df['opp_id'] = df['opp_team'].map(teammap)\n",
    "    df.sort_values(by='date', inplace=True)\n",
    "    df['series_key'] = df['team'] + '_' + df['opp_team'] + '_' + df['year'].astype(str)\n",
    "    series_index = df[['series_key', 'team', 'opp_team', 'TEAM_ID', 'opp_id', 'year']].drop_duplicates()\n",
    "    series_index_path = 'series_index.csv'\n",
    "    if os.path.exists(series_index_path):\n",
    "        existing_series_index = pd.read_csv(series_index_path)\n",
    "        combined_series_index = pd.concat([existing_series_index, series_index], ignore_index=True)\n",
    "        combined_series_index.drop_duplicates(subset=['series_key', 'team', 'TEAM_ID', 'opp_team', 'opp_id', 'year'], keep='last', inplace=True)\n",
    "        combined_series_index.to_csv(series_index_path, index=False)\n",
    "    else:\n",
    "        series_index.to_csv(series_index_path, index=False)\n",
    "    df.to_csv('playoff_data.csv', index=False)\n",
    "    series_dir = '../series/data'\n",
    "    os.makedirs(series_dir, exist_ok=True)\n",
    "    for key, group in df.groupby('series_key'):\n",
    "        safe_key = key.replace('/', '-').replace('\\\\', '-')\n",
    "        group.to_csv(os.path.join(series_dir, f'{safe_key}.csv'), index=False)\n",
    "    return df\n",
    "\n",
    "def check_directory_structure():\n",
    "    base_path = '../team'\n",
    "    if not os.path.exists(base_path):\n",
    "        return\n",
    "    for year_dir in os.listdir(base_path):\n",
    "        year_path = os.path.join(base_path, year_dir)\n",
    "        if os.path.isdir(year_path):\n",
    "            _ = [f for f in os.listdir(year_path) if f.endswith('.csv')]\n",
    "\n",
    "def run_pipeline(start_year=2024, end_year=2025):\n",
    "    check_directory_structure()\n",
    "    dates = get_dates(start_year, end_year)\n",
    "    if dates.empty:\n",
    "        return None\n",
    "    raw_df = fetch_game_csvs(dates)\n",
    "    if raw_df.empty:\n",
    "        return None\n",
    "    return process_and_save_series_data(raw_df, dates)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for year in range(2024,2026):\n",
    "        run_pipeline(year,year+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51997cbc-493a-497e-b3e1-8093d7eb1ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b73ab12-10c8-4697-a6ee-3fa9b9b314cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0621e1-4c02-411a-942c-3d1a3c80bbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
